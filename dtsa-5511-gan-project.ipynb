{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":21755,"databundleVersionId":1475600,"sourceType":"competition"}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Introduction","metadata":{}},{"cell_type":"markdown","source":"The objective of this project is to create a generative adversarial network (GAN) to generate pictures in the style of Monet. This is part of a rolling kaggle competition with a dataset provided by kaggle. \n\nDuring this project I will review the dataset, create a GAN model, generate a submission, and present the results. \n\nThe GAN model will be broken up into 3 main parts, the Discriminator, the Generator, and the Loss function. Together the three models will work together to generate the submission pictures. ","metadata":{}},{"cell_type":"markdown","source":"## 1.1 Importing Libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow_addons as tfa\n\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\nimport numpy as np\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. EDA","metadata":{}},{"cell_type":"markdown","source":"For exploratory data analysis (EDA) on this project lets just get our data loaded first. After loading the dataset lets look a few examples to get a better idea what we are working with. ","metadata":{}},{"cell_type":"markdown","source":"## 2.1 Load Data","metadata":{}},{"cell_type":"markdown","source":"First we need to set up a way to load the data. For this lets use the TFRecord files and define some functions.  ","metadata":{}},{"cell_type":"code","source":"# All images are set to 256x256 rgb\nsize = [256, 256]\nchannel = 3\n\n# function to read record and load image\n\ndef give_image(name):\n    tf_format = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.string)\n    }\n    single = tf.io.parse_single_example(name, tfrecord_format)\n    image = tf.image.decode_jpeg(single['image'], channels=channel)\n    image = (tf.cast(image, tf.float32) / 127.5) - 1\n    image = tf.reshape(image, [*size, channel])\n    image = decode_image(image)\n    \n    return image\n\n# load dataset\ndef give_data(name, labeled=True, ordered=False):\n    dataset = tf.data.TFRecordDataset(name)\n    dataset = dataset.map(give_image, num_parallel_calls=AUTOTUNE)\n    return dataset\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get path for files \npath_monet = '/kaggle/input/gan-getting-started/monet_tfrec'\npath_photo = '/kaggle/input/gan-getting-started/photo_tfrec'\n\n# load file names\nnames_monet = tf.io.gfile.glob(str(path_monet + '/*.tfrec')) \nnames_photo = tf.io.gfile.glob(str(path_photo + '/*.tfrec')) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## load dataset\n\nmonet = give_data(names_monet, labeled=True).batch(1)\nphoto = give_data(names_photo, labeled=True).batch(1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that the dataset is loaded lets look a few examples. ","metadata":{}},{"cell_type":"code","source":"# load example image from each set\nexample_monet = next(iter(monet_ds))\nexample_photo = next(iter(photo_ds))\n\n# plot example\n\nplt.subplot(121)\nplt.title('Photo')\nplt.imshow(example_photo[0] * 0.5 + 0.5)\n\nplt.subplot(122)\nplt.title('Monet')\nplt.imshow(example_monet[0] * 0.5 + 0.5)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model ","metadata":{}},{"cell_type":"markdown","source":"For this project the model being created is a GAN model. The GAN is made up of multiple parts. First a generator model that generates images. A discriminator model that classify images as real of fake. For this project it will classify as Monet or NOT Monet.  ","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Generator","metadata":{}},{"cell_type":"code","source":"# Generator \ndef generator():\n    model = keras.Sequential()\n\n    # Encoder\n    model.add(layers.Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=(256, 256, 3)))\n    model.add(layers.LeakyReLU(0.2))\n    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU(0.2))\n    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.LeakyReLU(0.2))\n\n    # Decoder\n    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.ReLU())\n    model.add(layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n    model.add(layers.BatchNormalization())\n    model.add(layers.ReLU())\n    model.add(layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh'))\n\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Discriminator","metadata":{}},{"cell_type":"code","source":"def discriminator(input_shape=(256, 256, 3)):\n    model = Sequential()\n\n    # First convolutional block\n    model.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=input_shape))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n\n    # Second convolutional block\n    model.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n\n    # Third convolutional block\n    model.add(Conv2D(256, (5, 5), strides=(2, 2), padding='same'))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.3))\n\n    # Flatten and dense layers\n    model.add(Flatten())\n    model.add(Dense(512))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(1, activation='sigmoid'))\n\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Loss Function","metadata":{}},{"cell_type":"code","source":"# loss function\nloss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n\n# optimizer\nopt = tf.keras.optimizers.Adam(1e-4)\n\n# disc loss\ndef discriminator_loss(real_output, fake_output):\n    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n    total_loss = real_loss + fake_loss\n    return total_loss\n\n# gen loss\ndef generator_loss(fake_output):\n    return cross_entropy(tf.ones_like(fake_output), fake_output)\n\n# trainable function\ndef make_trainable(model, trainable):\n    for layer in model.layers:\n        layer.trainable = trainable","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.4 GAN Model","metadata":{}},{"cell_type":"code","source":"# Build models\ngenerator = generator()\ndiscriminator = discriminator()\n\n# Compile models\ndiscriminator.compile(optimizer= opt, loss= loss)\ngenerator.compile(optimizer= opt, loss= loss)\n\ngan = Sequential([\n    generator,\n    discriminator\n])\n\ngan.summary()\n\ngan.compile(optimizer= opt, loss= loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.5 Train Model","metadata":{}},{"cell_type":"markdown","source":"## 3.6 Submission File","metadata":{}},{"cell_type":"markdown","source":"# 4. Results/Analysis","metadata":{}},{"cell_type":"markdown","source":"# 5. Conclusion","metadata":{}}]}